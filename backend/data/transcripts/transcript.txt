 What will be the most important trends in AI in 2026?  Well, we take a stab at this every year with some success, I would say.  And this time out, I have the knowledgeable assistance of my colleague Aaron Bogh,  who went to help us out.  Well, yeah, you know, after your prediction of infinite memory last year,  I thought maybe you could use just a little bit of help.  Yeah, that's fair.  Well, how about we each take four trends each?  That sounds good.  How about you first?  All right, OK, so my number one trend of 2026 is multi-agent orchestration.  Now, last year, we said 2025 was the year of the agent.  AI agents that can reason and plan and take action on a task.  And agents, I think it's fair to say, really delivered.  There are numerous agent platforms for tasks like coding and basic computer use.  But no single agent really excels at everything.  So what if you had a whole team of agents working together?  So maybe we've got an agent here that kind of acts as a planner agent  that decomposes goals into steps.  Maybe we have some worker agents here that do different steps,  like one specializes in writing code, others call APIs and so forth.  And then perhaps we have a critic agent that evaluates outputs and flags issues.  And these agents collaborate under a coordinating layer that is the orchestrator.  Multi-agent setups like this help introduce cross-checking,  where one agent checks the other agent's work,  and it can break problems into more discrete verifiable steps.  Well, great. So how can I really follow that trend?  Well, I think I might just have one.  So the second one is going to be the digital labor workforce.  So now these are digital workers that are autonomous agents that can do a couple of items.  So the first one is they can parse a task by interpreting multimodal input.  So after preparation, the worker then executes what's called a workflow.  Now, this is where at the end of an action plan,  you know, it would follow a sequence of steps,  but then it has to be integrated into some sort of system that then in turn can take action.  And these can be downstream components.  Now, these systems are then further enhanced by what we call human and the loop AI,  which then provides a couple of items.  The first one would be oversight.  The next one would be correction.  And then we're looking at these strategic guidance or these rails  to ensure that all of these agents are doing what they're supposed to be doing.  Now, this overall trend will create a force multiplying effect to extend human capability.  Now, trend number three is physical AI.  Now, we all know that large language models, they generate text like ABC.  And then there are other models as well.  So for example, there are plenty of diffusion image models and they generate pixels.  They generate images.  These are all operating in digital space.  Now, physical AI is about models that understand and interact  with the world that we live in, the real 3D world.  And this is about models that can perceive their environment, reason about physics,  and that can take physical action like robotics.  So previously getting a robot like this to do something useful meant programming explicit rules.  So if you see an obstacle, you should turn left, for example.  And it was all done by humans.  It was up to, yeah, smart guys like this to code these rules.  Now, physical AI kind of flips that around.  So you train models in simulation that simulate the real world.  And it learns to understand how objects behave in the physical world,  how gravity works, how to grasp something without crushing it.  Now, these models are sometimes called world foundation models.  They're generative models that can create and understand 3D environments.  They can predict what happens next in a physical scene.  And in 2026, many of these world models are taking things like those humanoid robots  that you found there, Aaron, and they're taking them from research to commercial production.  Physical AI is scaling.  Well, Martin, you just took my trend.  But let's just go ahead and say number four is about social computing.  Now, this is a world where many agents and humans operate within the shared AI fabric.  So say if I have an agent here and then a human here.  So they're going to be connected through this fabric.  And here, if I have information that flows between the two,  they begin to understand each other.  And then they can gather what the intent is going to be.  And then once they have the intent and information, they have actions.  They can affect each other or maybe even the environment of which they're in.  But all of this flows seamlessly across this system.  It's the shared space that enables collaboration, context exchange,  as well as event-effective understanding.  Now, the outcome is really an empathetic emergent network of these interactions.  It's what we call this collective intelligence or this real-world swarm computing.  So teams of agents, digital labor, humanoid robots,  and tech that can understand me with effective computing.  2026 could be quite the year and we're only halfway through the trends.  So trend number five, that is verifiable AI.  The EU AI Act is coming and by mid-2026, it becomes fully applicable.  And think of this a little bit like GDPR, but for artificial intelligence.  Now, the core idea here is that AI systems, especially high-risk ones,  need to be auditable and they also need to be traceable.  Now, what does that mean?  Well, it means a few things.  It means documentation.  So if you're building high-risk AI, you need technical docs  that demonstrate compliance to how you tested the models  and the risks that you identified.  It means transparency.  So users need to know when they're interacting with the machine.  So things like synthetic text, they need to be clearly labeled.  And it means data lineage.  You need to be able to summarize where your training data came from  and prove you respected copyright opt-outs.  And just like how GDPR has shaped global privacy, not just folks in the EU,  the EU AI Act will probably set the template for AI governance worldwide.  Wow, that's great.  And, you know, trend number six, right, it really changes everything,  but it also changes nothing at the same time.  And now this is where we put in quantum utility everywhere.  So 2026 is where we start to see this quantum computing  to reliably start solving real-world problems better, faster,  or more efficiently than classical computing methods.  Now at this point, we have this quantum utility scale.  It's these systems that begin working alongside and together  with classical infrastructure to deliver these practical value in everyday workflows.  Now this is going to help with optimization.  And then we'll also look at simulation and decision-making.  Now all three of these tasks were previously out of reach  within the classical realm.  But this hybrid quantum classical error,  it will begin to transform quantum computing into this mainstream paradigm  as it's going to be woven into our everyday business operations.  Now my trend number seven is reasoning at the edge.  Now, last year we talked about very small models,  models with just a few billion parameters  that don't need huge data centers to run.  They work on your laptop or maybe even your phone.  Well, in 2026, those small models are learning to think.  So if we think about the best models that we have today, the frontier models,  well, pretty much all of them now use something called inference time compute.  They spend extra time thinking before giving you an answer,  working through problems step by step.  Now the trade-off for that is they need more compute.  But here's what's changing.  Essentially, teams have figured out how they can distill  all of this reasoning information into smaller models.  So now these smaller models can perform thinking as well.  You're taking massive reasoning models that generate tons of step by step solutions  and we're using that data to train the smaller models to reason the same way.  And that's resulting in reasoning models with only a few billion parameters.  They work offline, your data never leaves your device,  and there's no round-trip latency to a data center.  So for anything that's real-time or mission-critical,  having a model that can actually reason through a problem locally is a pretty big deal.  Yeah, so that's all very true, Martin.  But now our last and final trend is number eight.  So this is what we're calling amorphous hybrid computing.  So this is a future where both AI model topologies and the cloud infrastructure,  they blend into what's called a fluid computing backbone.  So AI models, they're shifting beyond just this pure transformer design, right?  They're beginning to evolve into these other architectures that integrate transformers  and we call them the state space models.  And then in 2026, you're also going to see different emerging algorithms  that would combine both the state space and transformers and other elements together, right?  And that's going to be really fun to watch, very artful.  And then at the same time, we have this cloud computing piece  that's becoming fully differentiated by combining many different chip types.  So we're going to have CPUs, GPUs, TPUs as well.  And finally, what we just talked about in trend six, quantum, we're going to have QPUs.  I did also want to mention a note that you'll see these neuromorphic chips that are coming out  and those emulate the brain.  But all of these are going to be put together right into this unified compute environment  where parts of each of these types of models,  they're going to be automatically mapped to the optimal compute substrate.  And this is really going to help to deliver this maximum performance and efficiency.  And you know what? Who knows?  But at this pace, probably not in 2026, but I think further out,  you might see DNA computing entering into the mix.  Well, those are some lofty goals.  And look, these are what we think are some of the biggest AI trends in 2026.  But what are we missing?  Which AI trend do you expect to be a big deal in 2026?  Yeah, let us know in the comments below.